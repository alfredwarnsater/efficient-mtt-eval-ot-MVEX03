{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681f9c77-b590-4012-b690-84f2ba0da6b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a15bb-0b64-41d2-9abd-1ba606640be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io as spio\n",
    "import torch\n",
    "import pulp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKg_gxPXX7SZ",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Definition of helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948bcf98-8c3a-42cd-9caa-7676108373f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simple_example(c, p):\n",
    "    T = 4\n",
    "    delta = c * 10\n",
    "    Delta = c * 2\n",
    "    m = 2\n",
    "    n = 2\n",
    "    X = np.ones((T, m, 1))\n",
    "    Y = np.ones((T, n, 1))\n",
    "    X[:, 0, 0] = -(delta + Delta) / 2 * X[:, 0, 0]\n",
    "    X[:, 1, 0] = -X[:, 0, 0]\n",
    "    Y[:2, 0, 0] = - delta / 2 * Y[:2, 0, 0]\n",
    "    Y[2:, 0, 0] = delta / 2 * Y[2:, 0, 0]\n",
    "    Y[:, 1, 0] = -Y[:, 0, 0]\n",
    "    return X, Y\n",
    "\n",
    "def generate_extreme_example(c, p):\n",
    "    T = 100\n",
    "    m = 2\n",
    "    n = 2\n",
    "    X = np.ones((T, m, 1))\n",
    "    Y = np.ones((T, n, 1))\n",
    "    X[:, 0, 0] = -10\n",
    "    X[:, 1, 0] = 10\n",
    "    Y[:(T // 2), 0, 0] = -10\n",
    "    Y[(T // 2):, 0, 0] = 10\n",
    "    Y[:(T // 2), 1, 0] = 10\n",
    "    Y[(T // 2):, 1, 0] = -10\n",
    "    return X, Y\n",
    "\n",
    "def d(x, y, c, p):\n",
    "    x_nan, y_nan = np.any(np.isnan(x)), np.any(np.isnan(y))\n",
    "    if x_nan and y_nan:\n",
    "        return 0\n",
    "    elif x_nan or y_nan:\n",
    "        return c / 2**(1 / p)\n",
    "    else:\n",
    "        return np.minimum(c, np.linalg.norm(x - y, ord=p)) # TODO: Is this correct?\n",
    "    \n",
    "def calculate_distance_matrices(X, Y, c, p):\n",
    "    T, m, _ = X.shape\n",
    "    T, n, _ = Y.shape\n",
    "    D = np.zeros((T, m + 1, n + 1))\n",
    "    for t in range(T):\n",
    "        for i in range(m + 1):\n",
    "            for j in range(n + 1):\n",
    "                if i == m:\n",
    "                    x = np.nan\n",
    "                else:\n",
    "                    x = X[t, i, :]\n",
    "                if j == n:\n",
    "                    y = np.nan\n",
    "                else:\n",
    "                    y = Y[t, j, :]\n",
    "                D[t, i, j] = d(x, y, c, p)**p\n",
    "    return D\n",
    "\n",
    "def generate_trajectories(T, m, l, birth_death_prob=0.5):\n",
    "    tau = l / T\n",
    "    F = np.kron(np.eye(2), np.array([[1, tau], [0, 1]]))\n",
    "    Q = np.kron(np.eye(2), np.array([[tau**3 / 3, tau**2 / 2], [tau**2 / 2, tau]]))\n",
    "    X = np.zeros((T, m, 4))\n",
    "    X[:] = np.nan\n",
    "    for i in range(m):\n",
    "        t_birth, t_death = 0, 0\n",
    "        while t_birth == t_death or t_birth < 0 or t_death >= T:\n",
    "            t_birth = np.random.geometric(birth_death_prob) - 1\n",
    "            t_death = T - (np.random.geometric(birth_death_prob) - 1)\n",
    "            if t_birth > t_death:\n",
    "                t_birth, t_death = t_death, t_birth\n",
    "        X[t_birth, i, (0, 2)] = np.random.multivariate_normal(np.ones(2), np.eye(2))\n",
    "        X[t_birth, i, (1, 3)] = np.random.multivariate_normal(-X[t_birth, i, (0, 2)], np.eye(2))\n",
    "        for t in range(t_birth + 1, t_death):\n",
    "            X[t, i, :] = np.random.multivariate_normal(F @ X[t - 1, i, :], Q)\n",
    "    return X[:, :, (0, 2)]\n",
    "\n",
    "def add_track_switching(X, n_switches, switch_cutoff, max_switch_attempts):\n",
    "    X = X.copy()\n",
    "    switches = 0\n",
    "    attempted_switches = 0\n",
    "    completed_switches = set()\n",
    "    while switches < n_switches and attempted_switches < max_switch_attempts:\n",
    "        t, i, j = np.random.randint(0, X.shape[0]), np.random.randint(0, X.shape[1]), np.random.randint(0, X.shape[1])\n",
    "        if i == j:\n",
    "            continue\n",
    "        if np.linalg.norm(X[t, i, :] - X[t, j, :]) < switch_cutoff and (t, i, j) not in completed_switches:\n",
    "            tmp = X[t:, i, :].copy()\n",
    "            X[t:, i, :] = X[t:, j, :].copy()\n",
    "            X[t:, j, :] = tmp\n",
    "            switches += 1\n",
    "            completed_switches.add((t, i, j))\n",
    "            completed_switches.add((t, j, i))\n",
    "        attempted_switches += 1\n",
    "    return X\n",
    "    \n",
    "def generate_structured_data(T, m_t, m_f, n_f, l, switch_cutoff, n_switches, max_switch_attempts, noise, birth_death_prob=0.5):\n",
    "    X_t = generate_trajectories(T, m_t, l, birth_death_prob)\n",
    "    Y_t = add_track_switching(X_t, n_switches, switch_cutoff, max_switch_attempts)\n",
    "    X_f = generate_trajectories(T, m_f, l, birth_death_prob)\n",
    "    Y_f = generate_trajectories(T, n_f, l, birth_death_prob)\n",
    "    X = np.concatenate((X_t, X_f), axis=1)\n",
    "    Y = np.concatenate((Y_t, Y_f), axis=1)\n",
    "    Y += np.random.normal(0, noise, size=Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e6763-2126-4773-be64-f8d29e7edaa9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Linear programming implementation of the T-GOSPA metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde8222d-6e9c-43f2-832d-4c4fa3c648d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_programming_solve(D, p, gamma, W_type=pulp.LpContinuous, logging=0):\n",
    "    if logging >= 1:\n",
    "        print(\"Setting up problem!\")\n",
    "    \n",
    "    T, m, n = D.shape\n",
    "    m, n = m - 1, n - 1\n",
    "\n",
    "    prob = pulp.LpProblem(\"GOSPA-T\", pulp.LpMinimize)\n",
    "\n",
    "    time_steps = list(range(T))\n",
    "    ground_truths = list(range(m))\n",
    "    estimates = list(range(n))\n",
    "\n",
    "    W = pulp.LpVariable.dicts(\"Assignment\", (time_steps, ground_truths + [m], estimates + [n]), 0, 1, W_type)\n",
    "    H = pulp.LpVariable.dicts(\"Track switching\", (time_steps[:-1], ground_truths, estimates), None, None, pulp.LpContinuous)\n",
    "\n",
    "    prob += (\n",
    "        pulp.lpSum([D[t, i, j] * W[t][i][j] for t in time_steps for i in ground_truths + [m] for j in estimates + [n]]) +\n",
    "            pulp.lpSum([gamma**p / 2 * H[t][i][j] for t in time_steps[:-1] for i in ground_truths for j in estimates]),\n",
    "        \"Sum of assignment and track switching cost\",\n",
    "    )\n",
    "\n",
    "    for t in time_steps:\n",
    "        for i in ground_truths:\n",
    "            prob += (\n",
    "                pulp.lpSum([W[t][i][j] for j in estimates + [n]]) == 1,\n",
    "                f\"Time step {t}, row {i} sum constraint\",\n",
    "            )\n",
    "        for j in estimates:\n",
    "            prob += (\n",
    "                pulp.lpSum([W[t][i][j] for i in ground_truths + [m]]) == 1,\n",
    "                f\"Time step {t}, column {j} sum constraint\",\n",
    "            )\n",
    "        prob += W[t][m][n] == 0\n",
    "        \n",
    "    for t in time_steps[:-1]:\n",
    "        for i in ground_truths:\n",
    "            for j in estimates:\n",
    "                prob += (\n",
    "                    H[t][i][j] >= W[t + 1][i][j] - W[t][i][j],\n",
    "                    f\"Time step {t}, element {i}, {j} track switching constraint (positive)\",\n",
    "                )\n",
    "                prob += (\n",
    "                    H[t][i][j] >= W[t][i][j] - W[t + 1][i][j],\n",
    "                    f\"Time step {t}, element {i}, {j} track switching constraint (negative)\",\n",
    "                )\n",
    "                \n",
    "    if logging >= 1:\n",
    "        print(\"Starting solve!\")\n",
    "        \n",
    "    status = prob.solve(pulp.PULP_CBC_CMD(msg=(logging == 2)))\n",
    "    objective_value = pulp.value(prob.objective)**(1/p)\n",
    "    node_cost = pulp.value(pulp.lpSum([D[t, i, j] * W[t][i][j] for t in time_steps for i in ground_truths + [m] for j in estimates + [n]]))\n",
    "    edge_cost = pulp.value(pulp.lpSum([gamma**p / 2 * H[t][i][j] for t in time_steps[:-1] for i in ground_truths for j in estimates]))\n",
    "    \n",
    "    W = np.array([[[W[t][i][j].varValue for i in range(m+1)] for j in range(n+1)] for t in range(T)])\n",
    "    H = np.array([[[H[t][i][j].varValue for i in range(m)] for j in range(n)] for t in range(T-1)])\n",
    "\n",
    "    if logging >= 1:\n",
    "        print(\"Done!\")\n",
    "        \n",
    "    return objective_value, node_cost, edge_cost, W, H, status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157f05fb-ac1a-4ade-b9ce-4b7a8292c6c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91269b6-10dd-4d1d-b3fd-d4ff7e7ff336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_1_solve(D, p, gamma, eta, rho, norm_type=float('inf'), logging=False, record_objective=False, record_convergence=False, max_its=torch.inf):\n",
    "    T, m, n = D.shape\n",
    "    m, n = m - 1, n - 1\n",
    "    \n",
    "    mu_x = torch.ones(m + 1)\n",
    "    mu_x[m] = n\n",
    "    mu_y = torch.ones(n + 1)\n",
    "    mu_y[n] = m\n",
    "\n",
    "    u_x = torch.zeros((T, m + 1))\n",
    "    u_y = torch.zeros((T, n + 1))\n",
    "\n",
    "    psi = torch.zeros((T, m + 1, n + 1))\n",
    "    psi_hat = torch.zeros((T, m + 1, n + 1))\n",
    "\n",
    "    eps = eta * torch.maximum(torch.max(D), torch.tensor(gamma**p)) * T\n",
    "    k = -D / eps\n",
    "\n",
    "    if logging:\n",
    "        print(\"Chosen epsilon:\", eps)\n",
    "    \n",
    "    U = torch.zeros((T - 1, m + 1, n + 1))\n",
    "    U_tilde = -U\n",
    "    \n",
    "    def bimarginal_projection(t):\n",
    "        return psi_hat[t, :, :] + psi[t, :, :] \n",
    "        \n",
    "    def quadmarginal_projection(t):\n",
    "        if t == T - 1:\n",
    "            return psi_hat[T - 1, :, :] + psi[T - 1, :, :]\n",
    "        else:\n",
    "            return u_x[t, :, None] + psi[t + 1, :, :] + psi_hat[t, :, :] + k[t, :, :] + u_y[t, :] + U[t, :, :] + U_tilde[t, :, :]\n",
    "    \n",
    "    def update_psi(t):\n",
    "        if t == T - 1:\n",
    "            psi[T - 1, :, :] = u_x[T - 1, :, None] + k[T - 1, :, :] + u_y[T - 1, :]\n",
    "        else:\n",
    "            psi[t, :, :] = torch.logsumexp(psi[t + 1, :, :] + U_tilde[t, :, :], dim=(0, 1)) + u_x[t, :, None] + k[t, :, :] + U[t, :, :] + u_y[t, :]\n",
    "\n",
    "    def update_psi_hat(t):\n",
    "        if t == 0:\n",
    "            psi_hat[t, :, :] = 0\n",
    "        else:\n",
    "            psi_hat[t, :, :] = torch.logsumexp(u_x[t - 1, :, None] + psi_hat[t - 1, :, :] + k[t - 1, :, :] + U[t - 1, :, :] + u_y[t - 1, :], dim=(0, 1)) + U_tilde[t - 1, :, :]\n",
    "\n",
    "    def iterate_u():\n",
    "        update_psi_hat(t)\n",
    "        u_x[t, :] = u_x[t, :] + torch.log(mu_x) - torch.logsumexp(bimarginal_projection(t), axis=1)\n",
    "        update_psi(t)\n",
    "        u_y[t, :] = u_y[t, :] + torch.log(mu_y) - torch.logsumexp(bimarginal_projection(t), axis=0)\n",
    "        \n",
    "    def iterate_U():\n",
    "        update_psi(t)\n",
    "        update_psi_hat(t + 1)\n",
    "        P = quadmarginal_projection(t)\n",
    "        \n",
    "        U_tilde[t, :m, :n] = torch.clip(U_tilde[t, :m, :n] + 0.5 * logsubexp(bimarginal_projection(t)[:m, :n], P[:m, :n]) - 0.5 * logsubexp(bimarginal_projection(t + 1)[:m, :n], P[:m, :n]), 0, gamma**p / eps)\n",
    "        U[t, :m, :n] = -U_tilde[t, :m, :n]\n",
    "        \n",
    "        #U[t, :m, :n] = torch.clip(U[t, :m, :n] + 0.5 * logsubexp(bimarginal_projection(t)[:m, :n], P[:m, :n]) - 0.5 * logsubexp(bimarginal_projection(t + 1)[:m, :n], P[:m, :n]), 0, gamma**p / eps)#-gamma**p / eps, 0)\n",
    "        #U_tilde[t, :m, :n] = -U[t, :m, :n]\n",
    "        \n",
    "        \n",
    "    def compute_objective():\n",
    "        node_cost = 0\n",
    "        for t in range(T):\n",
    "            node_cost += torch.sum(torch.exp(bimarginal_projection(t)) * D[t, :, :])\n",
    "        edge_cost = 0\n",
    "        for t in range(T - 1):\n",
    "            edge_cost += gamma**p / 2 * torch.sum((torch.abs(torch.exp(bimarginal_projection(t + 1)[:m, :n]) - torch.exp(bimarginal_projection(t)[:m, :n]))))\n",
    "        return node_cost, edge_cost\n",
    "\n",
    "    def logsubexp(x, y):\n",
    "        if torch.any(y > x):\n",
    "            print(\"This should not happen! Try increasing floating-point precision!\")\n",
    "        else:\n",
    "            return x + torch.log(1.0 - torch.exp(y - x))\n",
    "\n",
    "    it_cnt = 0\n",
    "    node_costs = []\n",
    "    edge_costs = []\n",
    "    convergence = []\n",
    "    u = torch.cat((u_x.flatten(), u_y.flatten(), U.flatten(), U_tilde.flatten()))\n",
    "    u_prev = torch.zeros(u.shape)\n",
    "    relative_change_norm = torch.inf\n",
    "    \n",
    "    while relative_change_norm > rho and it_cnt < max_its:\n",
    "        u_prev = torch.clone(u)\n",
    "        for t in range(T - 1, -1, -1):\n",
    "            update_psi(t)\n",
    "        for t in range(T - 1):\n",
    "            iterate_u()\n",
    "            iterate_U()\n",
    "        t = T - 1    \n",
    "        iterate_u()\n",
    "        \n",
    "        u = torch.cat((u_x.flatten(), u_y.flatten(), U.flatten(), U_tilde.flatten()))\n",
    "        relative_change_norm =  torch.linalg.vector_norm(u - u_prev, ord=norm_type) / torch.linalg.vector_norm(u_prev, ord=norm_type)\n",
    "        it_cnt += 1\n",
    "        \n",
    "        if record_objective:\n",
    "            node_cost, edge_cost = compute_objective()\n",
    "            node_costs.append(node_cost)\n",
    "            edge_costs.append(edge_cost)\n",
    "            \n",
    "        if record_convergence:\n",
    "            convergence.append(relative_change_norm)\n",
    "        \n",
    "        if logging:\n",
    "            if it_cnt == 1 or it_cnt % logging == 0:\n",
    "                print(\"Iteration:\", it_cnt)\n",
    "                print(\"    Objective value:\", node_cost + edge_cost)\n",
    "                print(\"        Node cost:\", node_cost)\n",
    "                print(\"        Edge cost:\", edge_cost)\n",
    "                print(\"    Convergence:\", relative_change_norm)\n",
    "                print()\n",
    "        \n",
    "    if logging:\n",
    "        print(\"Done!\")\n",
    "    \n",
    "    node_cost, edge_cost = compute_objective()\n",
    "    \n",
    "    return (node_cost + edge_cost)**(1/p), node_cost, edge_cost, it_cnt, torch.tensor(node_costs), torch.tensor(edge_costs), torch.tensor(convergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21483a0-9209-4304-8234-72af773d1fea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Algorithm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f5788e-8bd4-4b16-b903-fd961566aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_2_solve(D, p, gamma, eta, rho, norm_type=float('inf'), logging=False, record_objective=False, record_convergence=False, max_its=torch.inf):\n",
    "    T, m, n = D.shape\n",
    "    m, n = m - 1, n - 1\n",
    "    \n",
    "    mu_x = torch.ones(m + 1)\n",
    "    mu_x[m] = n\n",
    "    mu_y = torch.ones(n + 1)\n",
    "    mu_y[n] = m\n",
    "    \n",
    "    u = torch.zeros((T, m + 1))\n",
    "    u_hat = torch.zeros((T, n + 1))\n",
    "    \n",
    "    psi = torch.zeros((T, m + 1, n + 1))\n",
    "    psi_hat = torch.zeros((T, m + 1, n + 1))\n",
    "    \n",
    "    D_tilde = torch.ones((n+1, n+1)) - torch.diag(torch.ones(n+1))\n",
    "    D_tilde[:n, n] = 1 / 2\n",
    "    D_tilde[n, :n] = D_tilde[:n, n]\n",
    "    D_tilde *= gamma**p\n",
    "    \n",
    "    eps = eta * torch.maximum(torch.max(D), torch.max(D_tilde)) * T\n",
    "    k_tilde = -D_tilde / eps\n",
    "    k = -D / eps\n",
    "    \n",
    "    if logging:\n",
    "        print(\"Chosen epsilon:\", eps)\n",
    "    \n",
    "    def iterate():\n",
    "        P = u[t, :, None] + psi_hat[t, :, :] + k[t, :, :] + psi[t, :, :] + u_hat[t, :]\n",
    "        u[t, :] = u[t, :] + torch.log(mu_x) - torch.logsumexp(P, axis=1)\n",
    "        P = u[t, :, None] + psi_hat[t, :, :] + k[t, :, :] + psi[t, :, :] + u_hat[t, :]\n",
    "        u_hat[t, :] = u_hat[t, :] + torch.log(mu_y) - torch.logsumexp(P, axis=0)\n",
    "    \n",
    "    def update_psi():\n",
    "        psi[t, :m, :] = torch.logsumexp((psi[t + 1, :m, :] + k[t + 1, :m, :] + u[t + 1, :m, None] + u_hat[t + 1, None, :])[:, :, None] + k_tilde[None, :, :], axis=1)\n",
    "        psi[t, m, :] = torch.logsumexp(psi[t + 1, m, :] + k[t + 1, m, :] + u[t + 1, m] + u_hat[t + 1, None, :], axis=(0, 1))\n",
    "    \n",
    "    def update_psi_hat():\n",
    "        psi_hat[t + 1, :m, :] = torch.logsumexp((psi_hat[t, :m, :] + k[t, :m, :] + u[t, :m, None] + u_hat[t, None, :])[:, :, None] + k_tilde[None, :, :], axis=1)\n",
    "        psi_hat[t + 1, m, :] = torch.logsumexp(psi_hat[t, m, :] + k[t, m, :] + u[t, m] + u_hat[t, None, :], axis=(0, 1))\n",
    "    \n",
    "    def compute_objective():\n",
    "        node_cost = 0\n",
    "        for t in range(T):\n",
    "            P = u[t, :, None] + psi_hat[t, :, :] + k[t, :, :] + psi[t, :, :] + u_hat[t, :]\n",
    "            node_cost += torch.sum(D[t, :, :] * torch.exp(P))\n",
    "        edge_cost = 0\n",
    "        for t in range(T - 1):\n",
    "            for i in range(m):\n",
    "                P = u_hat[t + 1, :, None] + psi[t + 1, i, :, None] + k[t + 1, i, :, None] + psi_hat[t, i, :] + k[t, i, :] + k_tilde + u_hat[t, :] + u[t, i] + u[t + 1, i]\n",
    "                edge_cost += torch.sum(D_tilde * torch.exp(P))\n",
    "        return node_cost, edge_cost\n",
    "        \n",
    "    it_cnt = 0\n",
    "    node_costs = []\n",
    "    edge_costs = []\n",
    "    convergence = []\n",
    "    u_concat = torch.cat((u.flatten(), u_hat.flatten()))\n",
    "    u_concat_prev = torch.zeros(u_concat.shape)\n",
    "    relative_change_norm = torch.inf\n",
    "    \n",
    "    while relative_change_norm > rho and it_cnt < max_its:\n",
    "        u_concat_prev = torch.clone(u_concat)\n",
    "        for t in range(T - 2, -1, -1):\n",
    "            update_psi()\n",
    "        for t in range(T - 1):\n",
    "            iterate()\n",
    "            update_psi_hat()\n",
    "        t = T - 1\n",
    "        iterate()\n",
    "        \n",
    "        u_concat = torch.cat((u.flatten(), u_hat.flatten()))\n",
    "        relative_change_norm =  torch.linalg.vector_norm(u_concat - u_concat_prev, ord=norm_type) / torch.linalg.vector_norm(u_concat_prev, ord=norm_type)\n",
    "        it_cnt += 1\n",
    "\n",
    "        if record_objective:\n",
    "            node_cost, edge_cost = compute_objective()\n",
    "            node_costs.append(node_cost)\n",
    "            edge_costs.append(edge_cost)\n",
    "        \n",
    "        if record_convergence:\n",
    "            convergence.append(relative_change_norm)\n",
    "        \n",
    "        if logging:\n",
    "            if it_cnt == 1 or it_cnt % logging == 0:\n",
    "                print(\"Iteration:\", it_cnt)\n",
    "                print(\"    Objective value:\", node_cost + edge_cost)\n",
    "                print(\"        Node cost:\", node_cost)\n",
    "                print(\"        Edge cost:\", edge_cost)\n",
    "                print(\"    Convergence:\", relative_change_norm)\n",
    "                print()\n",
    "        \n",
    "    if logging:\n",
    "        print(\"Done!\")\n",
    "    \n",
    "    node_cost, edge_cost = compute_objective()\n",
    "    \n",
    "    return (node_cost + edge_cost)**(1/p), node_cost, edge_cost, it_cnt, torch.tensor(node_costs), torch.tensor(edge_costs), torch.tensor(convergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43587fe-4ad4-41a2-8d90-e273d597983c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results: Convergence results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54af8a5b-8426-4165-8e90-f8379f8d406f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unstructured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e149d2f-b26a-40c3-8806-97984d0f591b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0253e0-bdd4-4bc4-890f-09343ceee214",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "torch.manual_seed(0)\n",
    "D = torch.rand((20, 17, 16))\n",
    "D[:, -1, -1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7077ae-a3c8-4e3e-a91b-02c34803d713",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Linear programming reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702510a-21fa-41a4-9831-1861ff6c7e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_value_lp, node_cost_lp, edge_cost_lp, W, _, _ = linear_programming_solve(D, p=1, gamma=0.1, logging=1)\n",
    "print(\"Objective value:\", objective_value_lp)\n",
    "print(\"    Node cost:\", node_cost_lp)\n",
    "print(\"    Edge cost:\", edge_cost_lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356e664e-0407-46d8-b2a8-29ed29740725",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff7c64-d0af-4999-8ca4-536747a35d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = D.to('cuda')\n",
    "with torch.device('cuda'):\n",
    "    objective_value, node_cost, edge_cost, it_cnt, node_costs, edge_costs, convergence = algorithm_1_solve(D, p=1, gamma=0.1, eta=0.5 * 1e-4, rho=1e-10, norm_type=2, \\\n",
    "                                                                                                           logging=100, record_objective=True, record_convergence=True, max_its=1000)\n",
    "save_path = \"experiments/convergence_unstructured_algorithm_1_\"\n",
    "torch.save(node_costs, save_path + \"node_costs.pt\")\n",
    "torch.save(edge_costs, save_path + \"edge_costs.pt\")\n",
    "torch.save(convergence, save_path + \"convergence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0e83b-3a35-4537-b655-fd10cc12a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"experiments/convergence_unstructured_algorithm_1_\"\n",
    "node_costs = torch.load(load_path + \"node_costs.pt\")\n",
    "edge_costs = torch.load(load_path + \"edge_costs.pt\")\n",
    "convergence = torch.load(load_path + \"convergence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddb3e9-c08e-48ba-8c4b-72a730181f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 17})\n",
    "relative_step_size = convergence.cpu()\n",
    "plt.semilogy(relative_step_size, color = \"b\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Relative Step Size\")\n",
    "plt.savefig(\"figures/convergence_unstructured_algorithm_1_relative_step_size.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca2927-6575-470f-99a8-337171f55b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_values = np.abs((node_costs + edge_costs).cpu() / objective_value_lp - 1)\n",
    "plt.semilogy(objective_values, color = \"r\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Relative Error\")\n",
    "plt.ylim((0.7*1e-3, 1e-1))\n",
    "plt.axhline(color=\"k\", linestyle=\":\")\n",
    "plt.savefig(\"figures/convergence_unstructured_algorithm_1_objective_value.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a5968-4804-47e5-ae45-b2fc5da79621",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final approximation:\", (node_costs + edge_costs).cpu()[-1])\n",
    "print(\"LP-solver:\", objective_value_lp)\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "print(\"Relative error:\", np.abs((node_costs + edge_costs).cpu()[-1] / objective_value_lp - 1))\n",
    "torch.set_printoptions(sci_mode=None)\n",
    "print(\"Percent error:\", np.abs((node_costs + edge_costs).cpu()[-1] / objective_value_lp - 1) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d927242-a707-4b3a-879a-01bcf256f611",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Algorithm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9cc7e5-6460-4ddc-a29d-55000d13f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = D.to('cuda')\n",
    "with torch.device('cuda'):\n",
    "    objective_value, node_cost, edge_cost, it_cnt, node_costs, edge_costs, convergence = algorithm_2_solve(D, p=1, gamma=0.1, eta=0.5 * 1e-4, rho=1e-10, norm_type=2, \\\n",
    "                                                                                                           logging=100, record_objective=True, record_convergence=True, max_its=1000)\n",
    "save_path = \"experiments/convergence_unstructured_algorithm_2_\"\n",
    "torch.save(node_costs, save_path + \"node_costs.pt\")\n",
    "torch.save(edge_costs, save_path + \"edge_costs.pt\")\n",
    "torch.save(convergence, save_path + \"convergence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8cf65-e4ab-4838-a295-b47ab4fc53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"experiments/convergence_unstructured_algorithm_2_\"\n",
    "node_costs = torch.load(load_path + \"node_costs.pt\")\n",
    "edge_costs = torch.load(load_path + \"edge_costs.pt\")\n",
    "convergence = torch.load(load_path + \"convergence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20efcd9-a8bd-4a85-98cb-88a14d746ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 17})\n",
    "relative_step_size = convergence.cpu()\n",
    "plt.semilogy(relative_step_size, color = \"b\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Relative Step Size\")\n",
    "plt.savefig(\"figures/convergence_unstructured_algorithm_2_relative_step_size.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c1ee7f-784a-4173-9303-3730040a72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_values = np.abs((node_costs + edge_costs).cpu() / objective_value_lp - 1)\n",
    "plt.semilogy(objective_values, color = \"r\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Relative Error\")\n",
    "plt.axhline(color=\"k\", linestyle=\":\")\n",
    "plt.savefig(\"figures/convergence_unstructured_algorithm_2_objective_value.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc21fc-2149-46b0-a7cc-26f6ff6326ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final approximation:\", (node_costs + edge_costs).cpu()[-1])\n",
    "print(\"LP-solver:\", objective_value_lp)\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "print(\"Relative error:\", np.abs((node_costs + edge_costs).cpu()[-1] / objective_value_lp - 1))\n",
    "torch.set_printoptions(sci_mode=None)\n",
    "print(\"Percent error:\", np.abs((node_costs + edge_costs).cpu()[-1] / objective_value_lp - 1) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e6074c-d1cb-46ad-a9d9-51ab09b4735d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8952aba-9c4d-4518-a130-04bd2ed3944c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c65108-f9d9-454d-b949-d1e8a18813ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "np.random.seed(0)\n",
    "X, Y = generate_structured_data(T=20, m_t=14, m_f=2, n_f=1, l=1, switch_cutoff=0.25, n_switches=20, max_switch_attempts=100000, noise=0.01, birth_death_prob=0.9)\n",
    "D = calculate_distance_matrices(X, Y, c=0.25, p=1)\n",
    "D = torch.from_numpy(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc9dba-c052-471f-baba-37127348cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:, :, 1], X[:, :, 0], \"r\", label = \"Ground Truth\")\n",
    "plt.plot(Y[:, :, 1], Y[:, :, 0], \"b:\", label = \"Estimate\")\n",
    "plt.axis('scaled')\n",
    "plt.grid()\n",
    "plt.xlabel(\"Horizontal Position\")\n",
    "plt.ylabel(\"Vertical Position\")\n",
    "plt.xlim((None, 3.5))\n",
    "plt.ylim((None, 3.5))\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "plt.savefig(\"figures/structured_data_visualization.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db2ce3-10aa-4865-9829-b5ea85c1550d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Linear programming reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0931231a-6e0f-4c29-b2fd-3b5e53a8d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_value_lp, node_cost_lp, edge_cost_lp, W, _, _ = linear_programming_solve(D, p=1, gamma=1, logging=1)\n",
    "print(\"Objective value:\", objective_value_lp)\n",
    "print(\"    Node cost:\", node_cost_lp)\n",
    "print(\"    Edge cost:\", edge_cost_lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b07a9c8-6140-400c-9a92-40822c57132f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1246bd-a04d-49ff-b454-1f35b0bf6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = D.to('cuda')\n",
    "with torch.device('cuda'):\n",
    "    objective_value, node_cost, edge_cost, it_cnt, node_costs, edge_costs, convergence = algorithm_1_solve(D, p=1, gamma=1, eta=1e-5, rho=1e-10, norm_type=2, \\\n",
    "                                                                                                           logging=100, record_objective=True, record_convergence=True, max_its=1000)\n",
    "save_path = \"experiments/convergence_structured_algorithm_1_\"\n",
    "torch.save(node_costs, save_path + \"node_costs.pt\")\n",
    "torch.save(edge_costs, save_path + \"edge_costs.pt\")\n",
    "torch.save(convergence, save_path + \"convergence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a17587-826b-412f-8255-27346025d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"experiments/convergence_structured_algorithm_1_\"\n",
    "node_costs = torch.load(load_path + \"node_costs.pt\")\n",
    "edge_costs = torch.load(load_path + \"edge_costs.pt\")\n",
    "convergence = torch.load(load_path + \"convergence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2dc85a-ceff-4c0a-82d1-4516df6246c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 17})\n",
    "relative_step_size = convergence.cpu()\n",
    "plt.semilogy(relative_step_size, color = \"b\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Relative Step Size\")\n",
    "plt.savefig(\"figures/convergence_structured_algorithm_1_relative_step_size.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b591be33-3f77-40fe-8dcf-4ad8e93c89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_values = np.abs((node_costs + edge_costs).cpu() / objective_value_lp - 1)\n",
    "plt.semilogy(objective_values, color = \"r\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Relative Error\")\n",
    "plt.axhline(color=\"k\", linestyle=\":\")\n",
    "plt.savefig(\"figures/convergence_structured_algorithm_1_objective_value.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b3043f-5d27-4883-8fac-857a352e4586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final approximation:\", (node_costs + edge_costs).cpu()[-1])\n",
    "print(\"LP-solver:\", objective_value_lp)\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "print(\"Relative error:\", np.abs((node_costs + edge_costs).cpu()[-1] / objective_value_lp - 1))\n",
    "torch.set_printoptions(sci_mode=None)\n",
    "print(\"Percent error:\", np.abs((node_costs + edge_costs).cpu()[-1] / objective_value_lp - 1) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f379c0c-0b77-4029-bd32-03e34174ef01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Algorithm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193b001-237f-4f90-bf56-5b96bee2bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = D.to('cuda')\n",
    "with torch.device('cuda'):\n",
    "    objective_value, node_cost, edge_cost, it_cnt, node_costs, edge_costs, convergence = algorithm_2_solve(D, p=1, gamma=1, eta=1e-5, rho=1e-10, norm_type=2, \\\n",
    "                                                                                                           logging=100, record_objective=True, record_convergence=True, max_its=1000)  \n",
    "save_path = \"experiments/convergence_structured_algorithm_2_\"\n",
    "torch.save(node_costs, save_path + \"node_costs.pt\")\n",
    "torch.save(edge_costs, save_path + \"edge_costs.pt\")\n",
    "torch.save(convergence, save_path + \"convergence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33199131-afa3-48fa-b480-9b9a6e0cf799",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"experiments/convergence_structured_algorithm_2_\"\n",
    "node_costs = torch.load(load_path + \"node_costs.pt\")\n",
    "edge_costs = torch.load(load_path + \"edge_costs.pt\")\n",
    "convergence = torch.load(load_path + \"convergence.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954b35a-4356-4d2b-8a19-5ea70545674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 17})\n",
    "relative_step_size = convergence.cpu()\n",
    "plt.semilogy(relative_step_size, color = \"b\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Relative Step Size\")\n",
    "plt.savefig(\"figures/convergence_structured_algorithm_2_relative_step_size.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c9969-bd42-4d5b-b95c-2e8197dd11b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_values = np.abs((node_costs + edge_costs).cpu() / objective_value_lp - 1)\n",
    "plt.semilogy(objective_values, color = \"r\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Relative Error\")\n",
    "plt.axhline(color=\"k\", linestyle=\":\")\n",
    "plt.savefig(\"figures/convergence_structured_algorithm_2_objective_value.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4650e25-adaf-4228-8287-c9df40af5e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Final approximation:\", (node_costs + edge_costs).cpu()[-1])\n",
    "print(\"LP-solver:\", objective_value_lp)\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "print(\"Relative error:\", np.abs((node_costs + edge_costs).cpu()[-1] / objective_value_lp - 1))\n",
    "torch.set_printoptions(sci_mode=None)\n",
    "print(\"Percent error:\", np.abs((node_costs + edge_costs).cpu()[-1] / objective_value_lp - 1) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8644e8a-39ac-46d0-a8b2-f46210005f99",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results: Regularization analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea61f2-aa9c-4ea2-a0e5-f2001867176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=None)\n",
    "etas = [1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1]\n",
    "final_objective_values = []\n",
    "\n",
    "for eta in tqdm(etas):\n",
    "    D = D.to('cuda')\n",
    "    with torch.device('cuda'):\n",
    "        objective_value, node_cost, edge_cost, it_cnt, node_costs, edge_costs, convergence = algorithm_2_solve(D, p=1, gamma=1, eta=eta, rho=1.5e-6, norm_type=2, \\\n",
    "                                                                                                               logging=100, record_objective=True, record_convergence=True, max_its=1e300)  \n",
    "    final_objective_values.append(objective_value)\n",
    "    \n",
    "    save_path = \"experiments/regularization_\" + str(eta) + \"_structured_algorithm_2_\"\n",
    "    torch.save(node_costs, save_path + \"node_costs.pt\")\n",
    "    torch.save(edge_costs, save_path + \"edge_costs.pt\")\n",
    "    torch.save(convergence, save_path + \"convergence.pt\")\n",
    "\n",
    "torch.save(final_objective_values, \"experiments/regularization_final_objective_values.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76a1176-b5f4-48e3-9d85-bdb93b21c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_objective_values = torch.load(\"experiments/regularization_final_objective_values.pt\")\n",
    "final_objective_values = [ov.cpu() for ov in final_objective_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76349786-2eb6-4a8a-a476-07ee2a1f2678",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scale_plot = True\n",
    "\n",
    "if log_scale_plot:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.loglog(etas, np.abs(torch.tensor(final_objective_values) / objective_value_lp - 1), \"go-\")\n",
    "    ax.invert_xaxis()\n",
    "    ax.grid()\n",
    "    ax.set_ylabel(\"Relative Error\")\n",
    "    ax.set_xlabel(\"Regularization Magnitude\")\n",
    "    fig.savefig(\"figures/regularization_analysis_algorithm_2.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "else:     \n",
    "    fig, ax = plt.subplots()\n",
    "    left, bottom, width, height = [0.5, 0.5, 0.4, 0.4]\n",
    "    axins = ax.inset_axes([left, bottom, width, height])\n",
    "    axins.grid()\n",
    "    axins.set_ylim((-0.002, 0.04))\n",
    "    axins.set_xlim((1e-3*1.2, 1e-5*0.8))\n",
    "    axins.semilogx(etas[:5], np.abs(torch.tensor(final_objective_values) / objective_value_lp - 1)[:5], \"go-\")\n",
    "    ax.axhline(color=\"k\", linestyle=\":\")\n",
    "    ax.semilogx(etas, np.abs(torch.tensor(final_objective_values) / objective_value_lp - 1), \"go-\")\n",
    "    ax.invert_xaxis()\n",
    "    ax.grid()\n",
    "    axins.invert_xaxis()\n",
    "    ax.indicate_inset_zoom(axins, edgecolor=\"black\", zorder=0)\n",
    "    axins.invert_xaxis()\n",
    "    ax.set_ylabel(\"Relative Error\")\n",
    "    ax.set_xlabel(\"Regularization Magnitude\")\n",
    "    fig.savefig(\"figures/regularization_analysis_algorithm_2.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d9dd8-1ca2-4cea-b3e6-63f48591a51d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results: Runtime analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20b58cb-c256-46d7-9476-325378bdde31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Varying number of trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9eb83-90e7-4703-abea-d60c9c1e9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float)\n",
    "np.random.seed(0)\n",
    "clk_id = time.CLOCK_MONOTONIC\n",
    "\n",
    "ms = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "ms.reverse()\n",
    "m_fs = [round(i / 10) for i in ms]\n",
    "m_ts = [ms[i] - m_fs[i] for i in range(len(ms))]\n",
    "Ts = [25 for _ in range(len(ms))]\n",
    "\n",
    "n_samples = 50\n",
    "printing = False\n",
    "\n",
    "timing_lp = np.zeros((n_samples, len(ms)))\n",
    "timing_alg_2_cpu = np.zeros((n_samples, len(ms)))\n",
    "error_alg_2_cpu = np.zeros((n_samples, len(ms)))\n",
    "timing_alg_2_gpu = np.zeros((n_samples, len(ms)))\n",
    "error_alg_2_gpu = np.zeros((n_samples, len(ms)))\n",
    "\n",
    "for i in trange(n_samples):\n",
    "    if printing:\n",
    "        print(f\"Sample {i+1}:\")\n",
    "    for j in range(len(ms)):\n",
    "        if printing:\n",
    "            print(f\"    Case: T = {Ts[j]}, m = {ms[j]}:\")\n",
    "        X, Y = generate_structured_data(T=Ts[j], m_t=m_ts[j], m_f=m_fs[j], n_f=m_fs[j], l=1, switch_cutoff=0.25, n_switches=ms[j], max_switch_attempts=100 * ms[j], noise=0.01, birth_death_prob=0.9)\n",
    "        D = calculate_distance_matrices(X, Y, c=0.25, p=1)\n",
    "        D = torch.from_numpy(D).float()\n",
    "        start_time = time.clock_gettime(clk_id)\n",
    "        objective_value_lp, node_cost_lp, edge_cost_lp, W, _, _ = linear_programming_solve(D, p=1, gamma=1, logging=False)\n",
    "        elapsed_time = time.clock_gettime(clk_id) - start_time\n",
    "        timing_lp[i, j] = elapsed_time\n",
    "        if printing:\n",
    "            print(\"        Linear programming:\")\n",
    "            print(\"            Objective value:\", objective_value_lp)\n",
    "            print(\"                Node cost:\", node_cost_lp)\n",
    "            print(\"                Edge cost:\", edge_cost_lp)\n",
    "            print(\"            Time:\", elapsed_time)\n",
    "\n",
    "        start_time = time.clock_gettime(clk_id)\n",
    "        objective_value, node_cost, edge_cost, it_cnt, node_costs, edge_costs, convergence = algorithm_2_solve(D, p=1, gamma=1, eta=1e-4, rho=1e-4, norm_type=2, logging=False, record_objective=False, record_convergence=False, max_its=1e300)\n",
    "        elapsed_time = time.clock_gettime(clk_id) - start_time\n",
    "        timing_alg_2_cpu[i, j] = elapsed_time\n",
    "        error_alg_2_cpu[i, j] = np.abs(objective_value / objective_value_lp - 1)\n",
    "        if printing:\n",
    "            print(\"        Algorithm 2 (CPU):\")\n",
    "            print(\"            Objective value:\", objective_value)\n",
    "            print(\"            Relative error:\", error_alg_2_cpu[i, j])\n",
    "            print(\"            Time:\", elapsed_time)\n",
    "        \n",
    "        start_time = time.clock_gettime(clk_id)\n",
    "        D = D.to('cuda')\n",
    "        with torch.device('cuda'):\n",
    "            objective_value, node_cost, edge_cost, it_cnt, node_costs, edge_costs, convergence = algorithm_2_solve(D, p=1, gamma=1, eta=1e-4, rho=1e-4, norm_type=2, logging=False, record_objective=False, record_convergence=False, max_its=1e300)\n",
    "        elapsed_time = time.clock_gettime(clk_id) - start_time\n",
    "        timing_alg_2_gpu[i, j] = elapsed_time\n",
    "        error_alg_2_gpu[i, j] = np.abs(objective_value.cpu() / objective_value_lp - 1)\n",
    "        if printing:\n",
    "            print(\"        Algorithm 2 (GPU):\")\n",
    "            print(\"            Objective value:\", objective_value)\n",
    "            print(\"            Relative error:\", error_alg_2_gpu[i, j])\n",
    "            print(\"            Time:\", elapsed_time)\n",
    "        \n",
    "save_path = \"experiments/runtime_targets_lp_\"\n",
    "torch.save(timing_lp, save_path + \"timing_lp.pt\")\n",
    "torch.save(timing_alg_2_cpu, save_path + \"timing_alg_2_cpu.pt\")\n",
    "torch.save(error_alg_2_cpu, save_path + \"error_alg_2_cpu.pt\")\n",
    "torch.save(timing_alg_2_gpu, save_path + \"timing_alg_2_gpu.pt\")\n",
    "torch.save(error_alg_2_gpu, save_path + \"error_alg_2_gpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917eafc4-864d-4022-a1fd-c1e4a5a6df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"experiments/runtime_targets_lp_\"\n",
    "timing_lp = torch.load(load_path + \"timing_lp.pt\")\n",
    "timing_alg_2_cpu = torch.load(load_path + \"timing_alg_2_cpu.pt\")\n",
    "error_alg_2_cpu = torch.load(load_path + \"error_alg_2_cpu.pt\")\n",
    "timing_alg_2_gpu = torch.load(load_path + \"timing_alg_2_gpu.pt\")\n",
    "error_alg_2_gpu = torch.load(load_path + \"error_alg_2_gpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3ec4c-2214-4a54-9ed0-569b27efa713",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.reverse()\n",
    "\n",
    "plt.plot(ms, timing_lp.mean(axis=0)[::-1], \"b-\", linewidth=1, marker=\".\", label=\"LP-solver\")\n",
    "plt.plot(ms, timing_alg_2_cpu.mean(axis=0)[::-1], \"r-\", linewidth=1, marker=\".\", label=\"Algorithm 2 (CPU)\")\n",
    "plt.plot(ms, timing_alg_2_gpu.mean(axis=0)[::-1], \"g-\", linewidth=1, marker=\".\", label=\"Algorithm 2 (GPU)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of targets\")\n",
    "plt.ylabel(\"Wall-clock time in seconds\")\n",
    "plt.savefig(\"figures/runtime_targets_timings.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa536296-c656-4ddc-9559-a00b40c613eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = error_alg_2_cpu.mean(axis=0)[::-1]\n",
    "maxs = error_alg_2_cpu.max(axis=0)[::-1]\n",
    "std = error_alg_2_cpu.std(axis=0)[::-1]\n",
    "\n",
    "plt.plot(ms, mean, \"r-\", linewidth=1, marker=\".\", label=\"Mean\")\n",
    "plt.plot(ms, maxs, \"k-\", linewidth=1, marker=\".\", label=\"Max\")\n",
    "plt.legend()\n",
    "plt.fill_between(ms, mean - std, mean + std, alpha=0.1, color = \"r\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of targets\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.savefig(\"figures/runtime_targets_error.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d334de1-5783-498f-b744-1e918f0f9b8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Varying number of time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0a17f-2464-44d8-bc05-a44ca15bac1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float)\n",
    "np.random.seed(0)\n",
    "clk_id = time.CLOCK_MONOTONIC\n",
    "\n",
    "Ts = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "ms = [30 for _ in range(len(Ts))]\n",
    "m_fs = [round(i / 10) for i in ms]\n",
    "m_ts = [ms[i] - m_fs[i] for i in range(len(Ts))]\n",
    "Ts.reverse()\n",
    "\n",
    "n_samples = 50\n",
    "printing = False\n",
    "\n",
    "timing_lp = np.zeros((n_samples, len(Ts)))\n",
    "timing_alg_2_cpu = np.zeros((n_samples, len(Ts)))\n",
    "error_alg_2_cpu = np.zeros((n_samples, len(Ts)))\n",
    "timing_alg_2_gpu = np.zeros((n_samples, len(Ts)))\n",
    "error_alg_2_gpu = np.zeros((n_samples, len(Ts)))\n",
    "\n",
    "for i in trange(n_samples):\n",
    "    if printing:\n",
    "        print(f\"Sample {i+1}:\")\n",
    "    for j in range(len(Ts)):\n",
    "        if printing:\n",
    "            print(f\"    Case: T = {Ts[j]}, m = {ms[j]}:\")\n",
    "        X, Y = generate_structured_data(T=Ts[j], m_t=m_ts[j], m_f=m_fs[j], n_f=m_fs[j], l=1, switch_cutoff=0.25, n_switches=ms[j], max_switch_attempts=100 * ms[j], noise=0.01, birth_death_prob=0.9)\n",
    "        D = calculate_distance_matrices(X, Y, c=0.25, p=1)\n",
    "        D = torch.from_numpy(D).float()\n",
    "        start_time = time.clock_gettime(clk_id)\n",
    "        objective_value_lp, node_cost_lp, edge_cost_lp, W, _, _ = linear_programming_solve(D, p=1, gamma=1, logging=False)\n",
    "        elapsed_time = time.clock_gettime(clk_id) - start_time\n",
    "        timing_lp[i, j] = elapsed_time\n",
    "        if printing:\n",
    "            print(\"        Linear programming:\")\n",
    "            print(\"            Objective value:\", objective_value_lp)\n",
    "            print(\"                Node cost:\", node_cost_lp)\n",
    "            print(\"                Edge cost:\", edge_cost_lp)\n",
    "            print(\"            Time:\", elapsed_time)\n",
    "\n",
    "        start_time = time.clock_gettime(clk_id)\n",
    "        objective_value, node_cost, edge_cost, it_cnt, node_costs, edge_costs, convergence = algorithm_2_solve(D, p=1, gamma=1, eta=1e-4, rho=1e-4, norm_type=2, logging=False, record_objective=False, record_convergence=False, max_its=1e300)\n",
    "        elapsed_time = time.clock_gettime(clk_id) - start_time\n",
    "        timing_alg_2_cpu[i, j] = elapsed_time\n",
    "        error_alg_2_cpu[i, j] = np.abs(objective_value / objective_value_lp - 1)\n",
    "        if printing:\n",
    "            print(\"        Algorithm 2 (CPU):\")\n",
    "            print(\"            Objective value:\", objective_value)\n",
    "            print(\"            Relative error:\", error_alg_2_cpu[i, j])\n",
    "            print(\"            Time:\", elapsed_time)\n",
    "        \n",
    "        start_time = time.clock_gettime(clk_id)\n",
    "        D = D.to('cuda')\n",
    "        with torch.device('cuda'):\n",
    "            objective_value, node_cost, edge_cost, it_cnt, node_costs, edge_costs, convergence = algorithm_2_solve(D, p=1, gamma=1, eta=1e-4, rho=1e-4, norm_type=2, logging=False, record_objective=False, record_convergence=False, max_its=1e300)\n",
    "        elapsed_time = time.clock_gettime(clk_id) - start_time\n",
    "        timing_alg_2_gpu[i, j] = elapsed_time\n",
    "        error_alg_2_gpu[i, j] = np.abs(objective_value.cpu() / objective_value_lp - 1)\n",
    "        if printing:\n",
    "            print(\"        Algorithm 2 (GPU):\")\n",
    "            print(\"            Objective value:\", objective_value)\n",
    "            print(\"            Relative error:\", error_alg_2_gpu[i, j])\n",
    "            print(\"            Time:\", elapsed_time)\n",
    "        \n",
    "save_path = \"experiments/runtime_time_steps_lp_\"\n",
    "torch.save(timing_lp, save_path + \"timing_lp.pt\")\n",
    "torch.save(timing_alg_2_cpu, save_path + \"timing_alg_2_cpu.pt\")\n",
    "torch.save(error_alg_2_cpu, save_path + \"error_alg_2_cpu.pt\")\n",
    "torch.save(timing_alg_2_gpu, save_path + \"timing_alg_2_gpu.pt\")\n",
    "torch.save(error_alg_2_gpu, save_path + \"error_alg_2_gpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26aca32-9cd5-4957-aa2c-6177ec34b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"experiments/runtime_time_steps_lp_\"\n",
    "timing_lp = torch.load(load_path + \"timing_lp.pt\")\n",
    "timing_alg_2_cpu = torch.load(load_path + \"timing_alg_2_cpu.pt\")\n",
    "error_alg_2_cpu = torch.load(load_path + \"error_alg_2_cpu.pt\")\n",
    "timing_alg_2_gpu = torch.load(load_path + \"timing_alg_2_gpu.pt\")\n",
    "error_alg_2_gpu = torch.load(load_path + \"error_alg_2_gpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f4017-66ca-4f73-8f5e-e89d141dabcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts.reverse()\n",
    "\n",
    "plt.plot(Ts, timing_lp.mean(axis=0)[::-1], \"b-\", linewidth=1, marker=\".\", label=\"LP-Solver\")\n",
    "plt.plot(Ts, timing_alg_2_cpu.mean(axis=0)[::-1], \"r-\", linewidth=1, marker=\".\", label=\"Algorithm 2 (CPU)\")\n",
    "plt.plot(Ts, timing_alg_2_gpu.mean(axis=0)[::-1], \"g-\", linewidth=1, marker=\".\", label=\"Algorithm 2 (GPU)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of Time Steps\")\n",
    "plt.ylabel(\"Wall-Clock Time in Seconds\")\n",
    "plt.savefig(\"figures/runtime_time_steps_timings.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3087747a-2913-4c2a-ae81-fcfa2c89ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = error_alg_2_cpu.mean(axis=0)[::-1]\n",
    "maxs = error_alg_2_cpu.max(axis=0)[::-1]\n",
    "std = error_alg_2_cpu.std(axis=0)[::-1]\n",
    "\n",
    "plt.plot(Ts, mean, \"r-\", linewidth=1, marker=\".\", label=\"Mean\")\n",
    "plt.plot(Ts, maxs, \"k-\", linewidth=1, marker=\".\", label=\"Max\")\n",
    "plt.legend()\n",
    "plt.fill_between(Ts, mean - std, mean + std, alpha=0.1, color = \"r\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of Time Steps\")\n",
    "plt.ylabel(\"Relative Error\")\n",
    "plt.savefig(\"figures/runtime_time_steps_error.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e071f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Counterexamples to the integrality of the linear program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c7f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counterexample:\n",
    "# X = np.array([[[0.5, 0.5, 1. , 3. ], [1.5, 0.5, 4. , 1.5]]])\n",
    "# Y = np.array([[[1.5, 0.5, 3. , 3. ], [1.5, 4.5, 4.5, 1. ]]])\n",
    "# c = 5.5\n",
    "# gamma = 0.5\n",
    "\n",
    "\n",
    "# Counterexample:\n",
    "# X = np.array([[[0.5, 0. , 4.5], [1. , 2. , 4. ]]])\n",
    "# Y = np.array([[[2. , 3. , 0.5], [0. , 0.5, 4. ]]])\n",
    "# c = 2\n",
    "# gamma = 1\n",
    "\n",
    "\n",
    "# Counterexample:\n",
    "# X = np.array([[[2.5, 0.5, 4. ], [0. , 0.5, 4.5]]])\n",
    "# Y = np.array([[[4.5, 4. ], [1.5, 0.5]]])\n",
    "# c = 2\n",
    "# gamma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35729c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_counter_example(T, m, n, roof):\n",
    "#    objective_value_continuous, objective_value_binary = 0, 0\n",
    "#    while True:\n",
    "#        X = np.random.randint(roof, size=(T, m, 1)) / 2\n",
    "#        Y = np.random.randint(roof, size=(T, m, 1)) / 2\n",
    "#        c = np.random.randint(roof) / 2 + 1\n",
    "#        gamma = np.random.randint(roof) / 2\n",
    "#        D = calculate_distance_matrices(X, Y, c, gamma)\n",
    "#        objective_value, node_cost, edge_cost, W, H, status = linear_programming_solve(D, 1, gamma, W_type=pulp.LpContinuous, logging=0)\n",
    "#        b_objective_value, b_node_cost, b_edge_cost, b_W, b_H, b_status = linear_programming_solve(D, 1, gamma, W_type=pulp.LpBinary, logging=0)\n",
    "#        print(objective_value, b_objective_value)\n",
    "#        if b_objective_value != objective_value:\n",
    "#            return X, Y, c, gamma\n",
    "\n",
    "#X, Y, c, gamma = generate_counter_example(10, 10, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bea541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array([[[2.5, 0.5, 4. ], [0. , 0.5, 4.5]]])\n",
    "#Y = np.array([[[4.5, 4. ], [1.5, 0.5]]])\n",
    "#gamma = 1\n",
    "\n",
    "#X = np.transpose(X, axes=(1, 2, 0))\n",
    "#Y = np.transpose(Y, axes=(1, 2, 0))\n",
    "\n",
    "#D = calculate_distance_matrices(X, Y, c, gamma)\n",
    "#objective_value, node_cost, edge_cost, W, H, status = linear_programming_solve(D, 1, gamma, W_type=pulp.LpContinuous, logging=0)\n",
    "#b_objective_value, b_node_cost, b_edge_cost, b_W, b_H, b_status = linear_programming_solve(D, 1, gamma, W_type=pulp.LpBinary, logging=0)\n",
    "#print(objective_value, b_objective_value)\n",
    "\n",
    "#print(W)\n",
    "#print(H)\n",
    "\n",
    "#print(b_W)\n",
    "#print(b_H)\n",
    "\n",
    "#print(pulp.LpStatus[status])\n",
    "#print(pulp.LpStatus[b_status])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c53ae-c30c-408f-a422-9a22db6a1999",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Illustration of Tracking Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gospa(D, W_type):\n",
    "    T, m, n = D.shape\n",
    "    m, n = m - 1, n - 1\n",
    "\n",
    "    prob = pulp.LpProblem(\"GOSPA\", pulp.LpMinimize)\n",
    "\n",
    "    time_steps = list(range(T))\n",
    "    ground_truths = list(range(m))\n",
    "    estimates = list(range(n))\n",
    "\n",
    "    W = pulp.LpVariable.dicts(\"Assignment\", (time_steps, ground_truths + [m], estimates + [n]), 0, 1, W_type)\n",
    "\n",
    "    prob += (\n",
    "        pulp.lpSum([D[t, i, j] * W[t][i][j] for t in time_steps for i in ground_truths + [m] for j in estimates + [n]]),\n",
    "        \"Assignment cost\",\n",
    "    )\n",
    "\n",
    "    for t in time_steps:\n",
    "        for i in ground_truths:\n",
    "            prob += (\n",
    "                pulp.lpSum([W[t][i][j] for j in estimates + [n]]) == 1,\n",
    "                f\"Time step {t}, row {i} sum constraint\",\n",
    "            )\n",
    "        for j in estimates:\n",
    "            prob += (\n",
    "                pulp.lpSum([W[t][i][j] for i in ground_truths + [m]]) == 1,\n",
    "                f\"Time step {t}, column {j} sum constraint\",\n",
    "            )\n",
    "        prob += W[t][m][n] == 0\n",
    "\n",
    "    status = prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "    objective_value = pulp.value(prob.objective)\n",
    "    W = np.array([[[W[t][i][j].varValue for i in range(m+1)] for j in range(n+1)] for t in range(T)])\n",
    "\n",
    "    return status, objective_value, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f0af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(15)\n",
    "m = 7\n",
    "n = 7\n",
    "X = np.random.random_sample((1, m, 2))\n",
    "Y = X + np.random.normal(0, 0.04, size=X.shape)\n",
    "D = calculate_distance_matrices(X, Y, 0.3, 1)\n",
    "status, gospa_val, W = gospa(D, pulp.LpBinary)\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        if W[0, j, i] > 0.99:\n",
    "                line = [(X[0, i, 0], Y[0, j, 0]), (X[0, i, 1], Y[0, j, 1])]\n",
    "                plt.plot(*line, \"k\", lw=1)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, 1)\n",
    "plt.plot(X[0, :, 0], X[0, :, 1], '+b', markersize=10, label='Ground Truth')\n",
    "plt.plot(Y[0, :, 0], Y[0, :, 1], 'xr', markersize=10, label='Estimate')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Horizontal Position\")\n",
    "plt.ylabel(\"Vertical Position\")\n",
    "plt.savefig(\"figures/localization_error.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d76835",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "m = 5\n",
    "n = 5\n",
    "X = np.random.random_sample((1, m, 2))\n",
    "Y = X + np.random.normal(0, 0.02, size=X.shape)\n",
    "D = calculate_distance_matrices(X, Y, 0.3, 1)\n",
    "status, gospa_val, W = gospa(D, pulp.LpBinary)\n",
    "\n",
    "X = np.concatenate((X, np.random.random_sample((1, 2, 2))), axis=1)\n",
    "Y = np.concatenate((Y, np.random.random_sample((1, 1, 2))), axis=1)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "plt.plot(X[0, m:, 0], X[0, m:, 1], 'ko', markersize=20, mfc='w')\n",
    "plt.plot(Y[0, n:, 0], Y[0, n:, 1], 'ko', markersize=20, mfc='w')\n",
    "plt.plot(X[0, :, 0], X[0, :, 1], '+b', markersize=10, label='Ground Truth')\n",
    "plt.plot(Y[0, :, 0], Y[0, :, 1], 'xr', markersize=10, label='Estimate')\n",
    "plt.legend(loc=3)\n",
    "plt.xlabel(\"Horizontal Position\")\n",
    "plt.ylabel(\"Vertical Position\")\n",
    "plt.savefig(\"figures/cardinality_error.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = generate_simple_example(0.2, 2)\n",
    "\n",
    "plt.vlines(range(1, 5), -1.5, 1.5, 'k', 'dotted')\n",
    "\n",
    "plt.plot(range(1, 5), X[:, 0, 0], 'ob-', label='Ground\\nTruth')\n",
    "plt.plot(range(1, 5), X[:, 1, 0], 'ob-')\n",
    "\n",
    "plt.plot(range(1, 5), Y[:, 0, 0], 'sr-', label='Estimate')\n",
    "plt.plot(range(1, 5), Y[:, 1, 0], 'sr-')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(\"Position\")\n",
    "plt.xticks(range(1, 5))\n",
    "plt.savefig(\"figures/track_switching_error.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis",
   "language": "python",
   "name": "master-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
